# SuperArchitect User Guide

This guide explains how to set up and use the SuperArchitect tool.

## What is SuperArchitect?

SuperArchitect is a command-line tool designed to assist in architectural planning. It takes a high-level user request, processes it through a structured workflow involving multiple AI models, and generates a detailed architectural plan in Markdown format.

## Getting Started: API Keys

To use SuperArchitect, you need API keys to connect to the AI services it uses. These keys grant SuperArchitect permission to leverage these AI models.

The primary services that can be used include:

*   **OpenAI:** Provides models like GPT series.
*   **Anthropic Claude:** Provider of Claude models.
*   **Google Gemini:** Google's family of AI models.

**How to get your keys:**

1.  **Sign Up:** Create accounts with each AI service provider you intend to use (e.g., OpenAI, Anthropic, Google).
2.  **Find the API Key Section:** Once logged in, look for sections like "API Keys," "Developer Settings," or similar in your account dashboard.
3.  **Create a New Key:** Generate a new API key as per the provider's instructions.
4.  **Copy Your Key:** Securely copy the generated key. It might only be displayed once.

**IMPORTANT:** Your API keys are sensitive credentials. **NEVER share them publicly or commit them to version control.** Keep them confidential.

## Installation

1.  **Navigate to Project Directory:** Open your terminal and go to the `SuperArchitect` project directory.
2.  **Install Dependencies:** Run the following command to install the necessary Python packages:
    ```bash
    pip install -r requirements.txt
    ```

## Configuration: Setting up `config.yaml`

SuperArchitect requires a configuration file named [`config.yaml`](config.yaml:0) to store your API keys and define which AI models to use for different tasks.

1.  **Find the Example:** In the `SuperArchitect` directory, locate the file named [`config.example.yaml`](config.example.yaml:0).
2.  **Make a Copy:** Create a copy of [`config.example.yaml`](config.example.yaml:0) in the *same* directory.
3.  **Rename the Copy:** Rename this copied file to exactly [`config.yaml`](config.yaml:0).

Now, open [`config.yaml`](config.yaml:0) with a text editor. You will need to configure the following key sections:

### 1. API Keys (`api_keys`)

This section is where you'll put the API keys you obtained.

```yaml
api_keys:
  openai: YOUR_OPENAI_API_KEY
  anthropic: YOUR_ANTHROPIC_API_KEY
  google_gemini: YOUR_GEMINI_API_KEY
  # Add other providers if needed
```
Replace `YOUR_PROVIDER_API_KEY` with your actual API key for each service you plan to use. If you don't have a key for a particular service, you can leave it as is or remove the line, but the tool won't be able to use models from that provider.

### 2. Model Provider Models (`model_provider_models`)

This section defines specific models from the providers that SuperArchitect can use. You assign a friendly name to each model string.

```yaml
model_provider_models:
  openai_model_name: "gpt-4-turbo"        # Example: Use your preferred OpenAI model
  anthropic_model_name: "claude-3-opus-20240229" # Example: Use your preferred Anthropic model
  google_gemini_model_name: "gemini-1.5-pro-latest" # Example: Use your preferred Google model
  # Define other models as needed
```
You can list multiple models from the same provider if desired, each with a unique friendly name.

### 3. Model Roles (`model_roles`)

This crucial section assigns the models defined in `model_provider_models` to specific roles within the SuperArchitect workflow.

```yaml
model_roles:
  decomposition_model: "google_gemini_model_name" # Assign a model (by its friendly name from above)
  consultation_models:
    - "anthropic_model_name"
    - "openai_model_name"
    # Add more models to try in sequence
  analyzer_model: "google_gemini_model_name"
  synthesis_handler: # For intro/conclusion generation
    provider: "anthropic" # "openai", "anthropic", or "google_gemini"
    model_name: "claude-3-sonnet-20240229" # Specific model string for this task
```

**Explanation of Model Roles:**

*   **`decomposition_model`**:
    *   **Function:** This AI model is responsible for the initial step. It takes your broad architectural planning query and breaks it down into smaller, logical sub-questions or substeps.
    *   **Configuration:** Assign one of the friendly model names defined in `model_provider_models`.
*   **`consultation_models`**:
    *   **Function:** This is a list of AI models. For each sub-question generated by the `decomposition_model`, SuperArchitect will try to get an answer from these models one by one, in the order they are listed. It uses the *first successful response* it receives. These models provide the core insights and information for each substep.
    *   **Configuration:** Provide a list of friendly model names.
*   **`analyzer_model`**:
    *   **Function:** This model works with the `AnalyzerEngine`. After a successful response is obtained for a sub-question from one of the `consultation_models`, the `analyzer_model` takes this response and structures it into a detailed JSON instructional guide. This structured format is then used for building the final plan.
    *   **Configuration:** Assign one of the friendly model names.
*   **`synthesis_handler`**:
    *   **Function:** This configuration is used by the `SynthesisEngine`. Its primary role is to generate the introductory and concluding sections of the final Markdown document. This helps frame the detailed, structured guides created for each substep with a coherent narrative.
    *   **Configuration:** This is an object where you specify the `provider` (e.g., "openai", "anthropic") and the `model_name` (the actual model string, not the friendly name from `model_provider_models`, e.g., "claude-3-sonnet-20240229").

**Save the [`config.yaml`](config.yaml:0) file.** Remember this file contains sensitive API keys, so keep it secure.

## SuperArchitect Workflow

The tool follows a structured process to generate architectural plans:

1.  **Decomposition:**
    *   Your initial architectural query is processed by the `decomposition_model`.
    *   This model breaks down the query into a series of logical substeps, often formulated as questions.
2.  **Consultation (Per Question):**
    *   For each substep/question, SuperArchitect iterates through the list of `consultation_models`.
    *   It uses the first successful response obtained from these models.
3.  **Analysis (Per Substep):**
    *   The `AnalyzerEngine`, using the `analyzer_model`, takes the successful consultation response for a substep.
    *   It processes this response to generate a detailed instructional guide in JSON format.
4.  **Synthesis:**
    *   The `SynthesisEngine` collects all the JSON instructional guides.
    *   It assembles them into a final Markdown architectural plan.
    *   The `synthesis_handler` (if configured) generates the introduction and conclusion for this document.

## Running SuperArchitect

SuperArchitect is run from your command-line interface (Terminal, Command Prompt, PowerShell).

1.  **Open your terminal.**
2.  **Navigate to the Project Directory:** Use `cd` commands to go to the `SuperArchitect` directory where [`main.py`](main.py:0) is located.
3.  **Run the command:** Type the following, replacing the example query with your own:

    ```bash
    python main.py "your architectural planning query here"
    ```

    *Example:*
    ```bash
    python main.py "Design a scalable backend for a social media application focusing on real-time updates and media storage."
    ```

4.  **Await Output:** The tool will begin processing your query. This may take some time depending on the query's complexity and the responsiveness of the AI models.
    *   The final architectural plan will be saved as a Markdown file in the `output/` directory (e.g., `output/generated_architectural_plan_YYYYMMDD_HHMMSS.md`).
    *   Detailed execution logs are saved in the `logs/` directory.

## Deep Research Module

SuperArchitect can optionally use a deep research module to gather additional context for the AI models. This feature is configured in [`config.yaml`](config.yaml:0) and detailed further in [`RESEARCH.md`](RESEARCH.md:0).

### Enabling/Disabling in `config.yaml`

The research module is controlled via the `research` section in [`config.yaml`](config.yaml:0).

```yaml
research:
  enabled: true  # Set to true to enable, false to disable
  # ... other research-specific configurations (see RESEARCH.md)
```

### Command-Line Control

You can override the `config.yaml` setting for research using command-line flags:

*   `--research-only`: Runs only the research module and then exits. Useful for pre-gathering information.
    ```bash
    python main.py "your query" --research-only
    ```
*   `--skip-research`: Skips the research module, even if enabled in `config.yaml`.
    ```bash
    python main.py "your query" --skip-research
    ```

These options provide flexibility in how you leverage the research capabilities. For more details on configuring and using the research module, please refer to [`RESEARCH.md`](RESEARCH.md:0).